\section{Materials and Methods}

\subsection*{Animals}
All procedures were performed in accordance with the regulations of the Institutional Animal Care and Use Committee at Yale University. Animals were housed on a 12/12-h light–dark cycle (lights off at 19:00) in groups of three to five per cage. Ten adult (postnatal days 111–279) male mice with a C57Bl/6J (\#000664; Jackson Laboratory) genetic background were used. Although two subjects from these experiments were also used in an earlier study \citep{siniscalchi2016fast}, the data and analyses in this article have not been reported elsewhere.

\subsection*{Behavioral Setup}
Subjects were placed in a modified acrylic tube (8486K33; McMaster-Carr) and held head-fixed during the behavioral task by fastening an implanted head plate to a custom-made stainless-steel bracket (eMachineShop) couple to the tube. This setup limits gross body movements but allows for small postural adjustments and movement of the hind limbs. 

Two lick spouts, mounted on a 3D-printed plastic part, were placed on either side of the mouth to allow lateralized responses and corresponding delivery of water rewards. This basic two-choice setup was modeled after an earlier study \citep{guo2014flow}. Lick spouts were fabricated from 20-G hypodermic needles, which were cut and carefully filed with an abrasive wheel, and then soldered to a wire lead and connected to a battery-operated lick detection circuit \citep{slotnick2009simple}. Output signals from the detector were digitized with a USB data acquisition device (USB-201; Measurement Computing) plugged into a desktop computer. 

Water rewards were delivered through each spout by gravity-feed and actuated with a solenoid valve (EV-2-24; Clippard) controlled by TTL pulses from a second USB-201. Pulse duration for a single reward (2 \si{\uL}) was calibrated for each valve by sending 100 pulses and then weighing the ejected volume (a 15–20 ms TTL pulse was typically required). On double-reward trials, 4 \si{\uL} were delivered by using either a calibrated longer duration pulse or two single rewards separated by 100 ms. 

Auditory stimuli were played through a pair of computer speakers (S120; Logitech) placed in front of the animal. The task structure was automated using custom scripts written for Presentation (Neurobehavioral Systems, Inc.). 

During training, the behavioral apparatus was enclosed in the cabinet of an audiovisual cart (4731T74; McMaster-Carr) soundproofed with acoustic foam (5692T49; McMaster-Carr). For imaging, the setup was replicated within the enclosure of a two-photon microscope.

\subsection*{Two-choice Auditory Discrimination Task with Probabilistic Outcomes}
Mice were trained to perform a two-choice auditory discrimination task. To motivate participation, subjects were water restricted, as follows. Six days per week, water was provided only in a single daily training session, as a reward for correct choices. On the remaining day, a water bottle was placed in the home cage for 15 min. Three phases of training were used to shape the behavior, identical to those used in our prior study \citep{siniscalchi2016fast}. 

During phase one, mice were habituated to head fixation and trained to lick the left or right spout for water: each lick to either spout triggered the release of 4 \si{\uL} of water, with a minimum interval of 1 s between rewards. 

After attaining $>100$ rewards in a single session of phase one (1–2 days), subjects were advanced to phase two, in which they were required to lick for a similar number of rewards at each spout. In this case, water was only available from one ‘target’ spout at a time, with the target moving to the opposite side each time the mouse earned three consecutive rewards from a given target. Additionally, sound stimuli were introduced in association with rewarded licks (‘hits’) on a given spout. The stimuli were trains of four 500-ms-long logarithmic chirps, with starting and ending frequencies of either 5 and 15 kHz (‘upsweep’), or 15 and 5 kHz (‘downsweep’), respectively. Upsweeps were played immediately following a left hit, and downsweeps were played immediately following a right hit. Similar to phase one, a minimum interval of 1 s was imposed between rewards. 

After attaining $>100$ hits within a single session of phase two (1–2 days), subjects were advanced to phase three, in which they were trained to perform a two-choice sound discrimination task. Unlike the earlier two phases, in which the operant behavior was self-paced, phase three was structured into trials with a defined response period. Each trial began with the presentation of a 2-s-long sound cue (upsweeps or downsweeps, randomly drawn), which indicated the target spout for that trial. Upsweeps indicated ‘left’ and downsweeps indicated ‘right’. To earn a water reward, the subject was required to lick the target spout within the final 1.5 s of the cue (the ‘response window’). The first lick to either spout within the response window terminated the sound cue and triggered an immediate outcome: 2 \si{\uL} of water from the target spout for a hit or playback of a 2-s-long white noise sound for an ‘error’, in which the wrong spout was chosen. ‘Misses’ were defined as trials in which the mouse failed to lick within the response window. In any case, the next trial would begin 7 s after cue offset. Thus, trial durations ranged from 7.5 to 9 s, depending on response time. Each session was terminated automatically after twenty consecutive misses. 

For the current study, subjects were trained on the two-choice sound discrimination task to a high level of proficiency ($>90\%$ hit rate) and were then tested on a task variant with probabilistic outcomes. This variant was identical to phase three of training, except that correct responses could result in one of three outcomes: 2 \si{\uL} of water (‘single reward’) with 80\% probability, no reinforcement (‘omitted reward’) with 10\% probability, or 4 \si{\uL} of water (‘double reward’) with 10\% probability. In a subset of sessions (5/16, identified in Table \ref{tab:CC_table1}), the white noise sound used in error trials was also played at the time of an omitted reward. We analyzed the behavioral and neural data for those sessions separately but did not detect any obvious differences; therefore, we have presented the pooled results.

\input{./Figures/CC_table1}

\subsection*{Virus Injection and Cranial Window Implantation}
All subjects were treated pre-operatively with carprofen (5 mg/kg, s.c.; \#024751; Butler Animal Health) and dexamethasone (3 mg/kg, s.c.; Dexaject SP, \#002459; Henry Schein Animal Health). Anesthesia was then induced with 2\% isoflurane in oxygen, and the animal was placed on a water-circulating heating pad (TP-700; Gaymar Stryker). Following induction, isoflurane concentration was lowered to 1.5\% and the head was secured in a stereotaxic frame with ear bars (David Kopf Instruments).

The scalp was shaved with electric trimmers and cleaned with a povidone-iodine surgical scrub (Betadine; Perdue Products L.P.). A narrow portion of scalp was removed along the midline from the interaural line to a line visualized just posterior to the eyes. The incision was retracted to expose the dorsal aspect of the skull, which was then scrubbed briefly with 3\% hydrogen peroxide to aid in removal of the periosteum, and washed generously with artificial cerebrospinal fluid (aCSF; in mM: 5 KCl, 5 HEPES, 135 NaCl, 1 MgCl$_2$ and 1.8 CaCl$_2$; pH 7.3). 

A 3-mm-diameter circular craniotomy was made over the right hemisphere using a high-speed rotary drill (K.1070; Foredom), centered on a medial target within M2 (AP $+1.5$ mm, ML $-0.5$ mm relative to Bregma). The dura was left intact and was irrigated frequently with ACSF over the remainder of the procedure. 

An adeno-associated virus encoding GCaMP6s (AAV1-Syn-GCaMP6s-WPRE-SV40; Penn Vector Core) was infused at four AP-ML coordinates through a glass micropipette attached to a microinjection unit (Nanoject II; Drummond). The injection sites formed a 200-\si{\um}-wide square centered on the target location. Each site was injected with 46 nL of virus over 3 min, at a depth of 0.4 mm from the dura. To minimize backflow of the injected solution, the micropipette was left in place for 5 min after each infusion. A small amount of warmed agarose solution (Type III-A, High EEO agarose; 1.2\% in ACSF; \#A9793; Sigma Aldrich) was then applied along the perimeter of the craniotomy to fill the space between the cranial window and the surrounding tissue after implantation. 

The cranial window consisted of two concentric circular glass parts, glued together with UV-activated optical adhesive (NOA 61; Norland Products, Inc.): a 3-mm-diameter, \#1 thickness prefabricated glass coverslip (\#64-0720-CS-3R; Warner Instruments) and a 2-mm-diameter plug cut from a \#1 or 2 thickness glass coverslip. The window was carefully placed on the brain surface with the glass plug facing down, and then secured to the skull at the edge of the craniotomy using surgical tissue adhesive (Vetbond; 3M). Gentle downward pressure was applied to stabilize the implant during this procedure, using a wooden probe attached to the stereotaxic frame. A custom-made stainless-steel head plate (eMachineShop) was then bonded to the skull with dental cement (C\&B Metabond; Parkell Inc.), with care taken to cover any remaining exposed skull. 

Post-operative care was provided immediately and for three consecutive days following surgery. This consisted of analgesia (carprofen, 5 mg/kg, s.c.) and fluid support (preservative-free 0.9\% NaCl, 0.5 mL, s.c., up to twice daily). All animals were given a one-week post-operative recovery period prior to the onset of behavioral training.

\subsection*{Two-Photon Calcium Imaging}
The two-photon microscope (Movable Objective Microscope; Sutter Instrument) was controlled using ScanImage software \citep{pologruto2003scanimage}. The excitation source was a Ti:Sapphire ultrafast femtosecond laser (Chameleon Ultra II, Coherent). Beam intensity was modulated using a Pockels cell (350-80-LA-02; Conoptics) and blanked with an optical shutter (LS6ZM2; Uniblitz/Vincent Associates). The beam was focused through a high-numerical aperture objective (XLUMPLFLN, 20$\times$/0.95 NA; Olympus). Excitation wavelength was set to 920 nm, and the emission was collected behind a bandpass filter from 475 to 550 nm using a GaAsP photomultiplier tube (H7422P-40MOD; Hamamatsu). The time-averaged excitation intensity after the microscope objective was $\sim$100 mW. 

Time-lapse image frames were acquired at $256 \times 256$ pixels and a nominal frame rate of 3.62 Hz, using bidirectional raster scanning. To synchronize the behavioral and imaging data, a TTL pulse was sent by Presentation 1 s prior to the start of each trial. This TTL signal was assigned as an external trigger in ScanImage to initiate a new image file. Timestamps of the TTL pulses along with timestamps of other behavioral events were written to a text file by Presentation, allowing the image files to be aligned with behavioral events.

\subsection*{Analysis of Behavioral Data}
Timestamps of the behavioral events, including cue onsets, licks, and reinforcement onsets, were logged to a text file by Presentation. All further processing and analysis were done using custom scripts written in MATLAB (MathWorks, Inc.). The number of trials performed was defined as the number of trials in which either spout was licked within the response window. Correct rate was defined as the number of correct trials divided by the number of trials performed. Miss rate was defined as the number of misses divided by the total number of trials. The sensitivity index, or d-prime, was calculated as the difference between the inverse of the standard normal cumulative distribution for the correct rate on upsweep trials and the inverse of the standard normal cumulative distribution for the incorrect rate on downsweep trials.

\subsection*{Analysis of Imaging Data}
Raw time-lapse image stacks corresponding to each trial were saved as multipage TIF files by ScanImage. As a first processing step, the raw stacks were merged to a single TIFF. Timestamps for the first frame of each trial, as well as the external trigger, were extracted for alignment with behavior. The merged TIF file was then processed for x–y motion correction using either the TurboReg \citep{thevenaz1998pyramid} or moco \citep{dubbs2016moco} plug-in for ImageJ \citep{schneider2012nih}. Regions of interest (ROIs) were manually selected around cell bodies appearing in the maximal or average projection image, using a custom graphical user interface programmed in MATLAB. Pixel intensity values within each ROI were summed for each frame $t$ to obtain $F(t)$. The baseline fluorescence, $F_0(t)$, was estimated as the 10th percentile of $F(t)$  within a 10 min moving window centered on $t$. $\Delta F/F(t)$ was then calculated as the fractional change in $F(t)$  relative to $F_0(t)$.

\subsection*{Event-Aligned Activity and Choice Selectivity}
To obtain trial-averaged activity traces associated with a specific behavioral event (eg cue onset), we first aligned $\Delta F/F$ traces based on their timing relative to each instance of the event and then took the mean across traces. To estimate confidence intervals, we performed a bootstrapping procedure, as follows. For $N$ instances of a particular event, $N$ traces were resampled randomly with replacement and then averaged. This process was repeated 1000 times, in order to approximate the sampling distribution for the mean. Upper and lower bounds of the associated confidence interval were then estimated as percentiles of this distribution. 

Choice selectivity was calculated as the difference between cue-aligned, trial-averaged traces from trials in which the ipsilateral versus contralateral spout was chosen, divided by the sum of the two traces. Therefore, choice selectivity was a function of time that could take values from $-1$ to 1, with negative values indicating an ipsilateral preference and positive values indicating a contralateral preference. The mean choice selectivity from 2 to 4 s after cue onset was used as a scalar estimate in comparisons between double- and omitted-reward trials.

\subsection*{Multiple Linear Regression}
To characterize the relationship between task variables and the activity of individual neurons, we fit the following linear equation:

\begin{equation*}
\begin{split}
\frac{\Delta F}{F}(t) = a_0 \\
&+ a_1 C_{n}        + a_2 C_{n-1}       + a_3 C_{n-2} \\
&+ a_4 R_{n}        + a_5 R_{n-1}       + a_6 R_{n-2} \\ 
&+ a_{7}C_{n}R_{n}  + a_8C_{n-1}R_{n-1} + a_9C_{n-2}R_{n-2} \\ 
&+ \epsilon(t),\\
\end{split} 
\end{equation*}

\noindent where $\Delta F/F(t)$ is the fractional change in fluorescence at time $t$ relative to baseline; $C_{n}$, $C_{n-1}$, and $C_{n-2}$ are the choices made on the current trial, the prior trial and the trial before last, respectively; $R_{n}$, $R_{n-1}$, and $R_{n-2}$ are the outcomes for the current trial, the prior trial and the trial before last, respectively; $a_0$…$a_9$ are the regression coefficients; and $\epsilon (t)$ is the error term. 

Choices were dummy-coded as $-1$ for left licks and 1 for right licks. Outcomes were dummy-coded as 0 for single-reward trials, $-1$ for omitted-reward trials and 1 for double-reward trials. Error trials and misses were not analysed. Regression coefficients and their $p$-values were estimated for each 500 ms time bin $t$, within an interval from $-2$ to 6.5 s relative to cue onset. 

To summarize the pooled results from all experiments, the proportion of neurons with a $p$-value less than 0.01 was plotted over time for each predictor. The binomial test was used to determine whether this proportion was significantly different from chance level.

\subsection*{Decoding: Linear Discriminant Analysis}
To determine how reliably the subject’s choices were encoded in the neural ensemble activity, we constructed and tested classifiers based on linear discriminant analysis. All classifiers were constructed using the ‘classify’ function in MATLAB, with the ‘type’ parameter set to ‘linear’ (the default); this classification method fits a multivariate normal density function to each group, using a pooled estimate of covariance. 

Choices, $C_n$, were dummy-coded as $-1$ for left licks and 1 for right licks. For each 500 ms time bin $t$ within the interval from $-2$ to 6.5 s relative to cue onset, the $\Delta F/F(t)$ values of all neurons were incorporated into a trial-indexed set of population activity vectors, with each vector representing the $\Delta F/F(t)$ for all neurons in the corresponding trial. A Monte Carlo cross-validation procedure was then applied across trials, as follows. First, activity vectors from a randomly drawn 80\% of single-reward trials were used as the training set to construct a classifier. The classifier was then tested for accuracy using the activity vectors from the remaining 20\% of single-reward trials. 

Additionally, we tested the accuracy of the classifier at decoding choices in other trial types, ie double-reward, omitted-reward, and error trials. To estimate chance-level performance for each classifier, an identical classifier was constructed and tested, with the exception that the $C_n$ values within the training set were first shuffled randomly. 

To characterize the potential advantage of simultaneous recording, we compared the accuracy of classifiers trained on actual imaging data versus ‘pseudo-ensemble’ data in which simultaneity had been destroyed. To build a pseudo-ensemble, the $\Delta F/F(t)$  values for each cell were randomly shuffled across all training trials with the same $C_n$ value. Therefore, each pseudo-ensemble activity vector comprised $\Delta F/F(t)$  values drawn from many different trials, while preserving cell identity as well as choice and outcome specificities. Classifiers trained on pseudo-ensemble data versus real data were then compared for accuracy using the remaining (unshuffled) test trials. 

For all of the analyses described in this section, average decoding accuracy was estimated as the mean across 30 iterations. This iterative cross-validation procedure was repeated for each time bin $t$.

\subsection*{Decoding: Random Forests}
As a second approach to decoding choices from the population activity, we constructed and tested random forest classifiers \citep{breiman2001random}. Neural and behavioral data were treated in the same manner as for the linear discriminant analysis described above: choices, $C_n$, were dummy-coded as $-1$ and 1; time ranged in 500 ms increments from $-2$ to 6.5 s relative to cue onset; and single-reward trials were split into training and testing sets for 30 iterations of Monte Carlo cross-validation. For each iteration, a random forest classifier was trained using population activity vectors from a random sample of 80\% of trials and then tested on the remaining 20\%. 

The random forest algorithm is a bootstrap aggregation (‘bagging’) approach consisting of many decision trees. Each decision tree takes as input a set of features (eg the activity of cells in the neural ensemble) and arrives at a predicted binary response (eg left or right choice). It does so by comparing a subset of the features to a series of corresponding threshold values (‘splits’) learned from the training set through a process of greedy recursive partitioning. The overall predicted response of the random forest is the majority vote of the predicted responses across all trees. 

To construct each decision tree, $M$ population activity vectors were drawn randomly with replacement from the $M$ trials making up the training set. Each split in the tree comprised a threshold on the $\Delta F/F(t)$ value of one cell selected as the strongest predictor out of a randomly drawn subset of cells. A new subset was drawn randomly without replacement to determine each split. The number of cells in each subset was equal to the square root of $N$, where $N$ is the total number of cells in the imaged ensemble. 

To choose the number of trees, we tested a range of values and found that classifier performance saturated beyond ~50 trees; therefore, the number of trees was set to 100. The procedure was implemented by calling the ‘fitensemble’ function in MATLAB with the ‘Method’ parameter set to ‘Bag’, the ‘Type’ parameter set to ‘Classification’ and the ‘Learners’ parameter set to ‘Tree’. 

Additionally, in the same manner as we did for the linear discriminant analysis, we tested classifiers constructed using single-reward trials on other trial types, determined chance-level accuracy by training classifiers on shuffled choices, and characterized the advantage of simultaneous recording by comparing with random forest classifiers constructed using pseudo-ensemble data. For all decoding analyses described in this section, average decoding accuracy was estimated as the mean accuracy across all iterations. This entire procedure was repeated for each time bin $t$.

\subsection*{Decoding: Varying the Ensemble Size}
To determine how the number of neurons in an ensemble influenced decoding accuracy, we constructed and tested classifiers on neural data drawn from subsets of the imaged populations. Because the smallest ensemble imaged in our experiments had just over 30 neurons, we limited this analysis to ensemble sizes from 1 to 30 cells. We also limited the analysis to the time interval from 2 to 4 s from cue onset, the period in which our decoding analyses showed the highest decoding accuracy. 

For each ensemble size, a subset of the imaged cells was drawn randomly without replacement to produce an ensemble of predetermined size, and the process was repeated for 30 draws. For each draw, a classifier was constructed using a random subsample of 80\% of trials and then tested on the remaining trials. Decoding accuracy was estimated as the mean across draws. This iterative procedure was repeated for each ensemble size and for the two types of classifiers (linear discriminant and random forest).

\subsection*{Experimental Design and Statistical Analysis}
The structure of the task was fully automated using custom scripts written for Presentation, which randomized the sound cues and outcomes presented in each trial. No further blinding was used. 

Sample sizes are noted in the results and figure legends. No statistical analysis was employed to determine sample sizes; however, they were similar to those used elsewhere in the field. All behavioral and neural ensemble analyses were performed using a sample size of $N = 16$ imaging sessions from ten animals (Table \ref{tab:CC_table1}). For analyses of single-unit activity (Figs. \ref{fig:CC_fig4} \& \ref{fig:CC_fig5}), the sample size was $N = 771$ cells; a subsample of $n = 226$ choice-selective cells was considered in Figure \ref{fig:CC_fig5} (see Results). 

A total of seven sessions were excluded from the study prior to neural activity analysis for the following reasons: poor behavioral performance (overall correct rate $<80\%$, one session); too few trials completed and, therefore, fewer than five trials for at least one outcome type (three sessions); and residual movement artifacts after image motion correction (three sessions). 

All statistical analyses were performed in MATLAB. A paired design was used for comparisons across outcome conditions, and the likelihood $p$ of a false positive was estimated with a Wilcoxon signed-rank test. $p < 0.05$ was taken to indicate a significant difference. No corrections were made for multiple comparisons, but $p$-values are noted explicitly in the Results. For the multiple linear regression analysis (Fig. \ref{fig:CC_fig4}), the significance threshold for each predictor was set at $\alpha = 0.01$. Significant proportions were determined using a binomial test, with $\alpha = 0.01$. For neural ensemble analyses, chance-level accuracy of decoding choices from the neural activity was determined by testing classifiers constructed using shuffled choices.